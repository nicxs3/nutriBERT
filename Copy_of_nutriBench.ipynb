{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicxs3/nutriBERT/blob/main/Copy_of_nutriBench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GcXEkUBlvql"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence-transformers scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"/train.csv\")\n",
        "val_df = pd.read_csv(\"/val.csv\")\n",
        "test_df = pd.read_csv(\"/test.csv\")\n"
      ],
      "metadata": {
        "id": "EjnwiG8_mHn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(train_df[\"query\"])\n",
        "X_val = vectorizer.transform(val_df[\"query\"])\n",
        "\n",
        "model = Ridge()\n",
        "model.fit(X_train, train_df[\"carb\"])\n",
        "preds = model.predict(X_val)\n",
        "\n",
        "mae = mean_absolute_error(val_df[\"carb\"], preds)\n",
        "print(\"Validation MAE:\", mae)\n"
      ],
      "metadata": {
        "id": "yRsxVDjRmRcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used TF-IDF for preprocessing and a Ridge Regression model, Validation MAE: 14.7717"
      ],
      "metadata": {
        "id": "QDlYDj4-du1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n"
      ],
      "metadata": {
        "id": "71SO4CqVejEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ],
      "metadata": {
        "id": "6wbqy6Gihx8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Encode text descriptions into 384-dimensional vectors\n",
        "X_train = model.encode(train_df['query'].tolist())\n",
        "X_val = model.encode(val_df['query'].tolist())\n",
        "\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(128, 64), max_iter=500, random_state=42)\n",
        "mlp.fit(X_train, train_df['carb'])\n",
        "\n",
        "preds = mlp.predict(X_val)\n",
        "mae = mean_absolute_error(val_df['carb'], preds)\n",
        "print(\"Validation MAE:\", mae)\n"
      ],
      "metadata": {
        "id": "sL2gMBNihzxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence-BERT for preprocessing and MLP model, Valdiation MAE: 9.8682"
      ],
      "metadata": {
        "id": "pJHYr6gBjGF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "lHmNO-eondeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('/train.csv')\n",
        "val_df = pd.read_csv('/val.csv')\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"query\"], padding=\"max_length\", truncation=True, max_length=64)\n",
        "\n"
      ],
      "metadata": {
        "id": "HHCD-CwltyJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NutriDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.encodings = tokenizer(df[\"query\"].tolist(), truncation=True, padding=\"max_length\", max_length=64)\n",
        "        self.labels = df[\"carb\"].tolist()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "metadata": {
        "id": "rJskWwb1uAsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = NutriDataset(train_df, tokenizer)\n",
        "val_dataset = NutriDataset(val_df, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "XA7NMzCuuE4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "import torch.nn as nn\n",
        "\n",
        "class BertRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertRegressor, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.pooler_output\n",
        "        return self.regressor(cls_output).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "oWolH-A9uIwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "import torch\n",
        "\n",
        "model = BertRegressor()\n",
        "model.to(\"cuda\")\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.L1Loss()  # MAE Loss\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
        "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
        "            attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
        "            labels = batch[\"labels\"].to(\"cuda\")\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            val_preds.extend(outputs.cpu().numpy())\n",
        "            val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_mae = mean_absolute_error(val_labels, val_preds)\n",
        "    print(f\"Epoch {epoch+1}: Validation MAE = {val_mae:.4f}\")\n",
        "\n",
        "torch.save(model, \"full_model.pt\")\n"
      ],
      "metadata": {
        "id": "6v60UfcauLMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "model = torch.load(\"full_model.pt\", weights_only=False)\n",
        "model.to(\"cuda\")\n",
        "model.eval()\n",
        "preds, targets = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
        "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
        "        labels = batch[\"labels\"].to(\"cuda\")\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds.extend(outputs.cpu().numpy())\n",
        "        targets.extend(labels.cpu().numpy())\n",
        "\n",
        "mae = mean_absolute_error(targets, preds)\n",
        "print(\"Validation MAE:\", mae)\n"
      ],
      "metadata": {
        "id": "uMMcYepXulTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "at 5 epochs MAE: 10.46 --\n",
        "at 10 epochs MAE: 8.726 --\n",
        "at 20 epochs MAE: 7.0649\n"
      ],
      "metadata": {
        "id": "4Lo98iST2cf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_values = [\n",
        "    14.0509, 12.7274, 11.5398, 10.9161, 10.5559,\n",
        "    9.6476, 9.3707, 9.2629, 8.7126, 8.6234,\n",
        "    8.2747, 8.0455, 7.8250, 7.6647, 7.4687,\n",
        "    7.5083, 7.1884, 7.0454, 7.0130, 7.0650\n",
        "]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, len(mae_values) + 1))\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs, mae_values, marker='o', linestyle='-', linewidth=2)\n",
        "plt.title(\"Validation MAE over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.grid(True)\n",
        "plt.xticks(epochs)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vuh0RvKIEB4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/test.csv\")\n",
        "\n",
        "# Tokenize the text using the same tokenizer\n",
        "test_encodings = tokenizer(\n",
        "    test_df[\"query\"].tolist(),\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=64,\n",
        "    return_tensors=\"pt\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Mkix0sjrFr2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "test_dataset = TestDataset(test_encodings)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "tXQylzdxG1T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load model\n",
        "model = torch.load(\"full_model.pt\", weights_only=False)\n",
        "model.to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "# 2. Make predictions\n",
        "predicted_carbs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
        "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        predicted_carbs.extend(outputs.cpu().numpy())\n",
        "\n",
        "# 3. Attach predictions to test_df\n",
        "test_df[\"predicted_carb\"] = predicted_carbs\n",
        "\n",
        "# 4. Save to CSV\n",
        "test_df.to_csv(\"nutribench_test_with_predictions.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "t6s4vutSG14x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}